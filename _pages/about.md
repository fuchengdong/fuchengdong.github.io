---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
Hi! I'm Chengdong Fu, a Machine Learning Engineer with 3 years of industry experience specializing in generative AI and computer vision. My expertise lies in designing controllable generative models through semantic guidance and hierarchical control mechanisms, with a focus on modular, plug-and-play architectures. 

I'm interested in bridging visual understanding and controllable generation in AI systems. Specifically, I wish to use computer vision and multi-modal learning algorithms to develop efficient personalization techniques for diffusion models, Enabling rich, fine-grained control over user interactions for customized content creation experiences.


Education
======

* **M.S. in Data Science** <span style="float: right;">Feb. 2022 â€“ Feb. 2023</span><br>
  [<span style="color: #ff8c42;">the University of Sydney</span>](https://www.sydney.edu.au/), Sydney, AU
  
* **B.S. in Computer Science** <span style="float: right;">Mar. 2018 â€“ Aug. 2021</span><br>
  [<span style="color: #ff8c42;">the University of Sydney</span>](https://www.sydney.edu.au/), Sydney, AU

Featured Projects
======

<style>
.project-cards {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
  gap: 20px;
  margin: 20px 0;
}

.project-card {
  background: #ffffff;
  border: 1px solid #e0e0e0;
  border-radius: 8px;
  padding: 20px;
  transition: all 0.3s ease;
  box-shadow: 0 2px 4px rgba(0,0,0,0.05);
}

.project-card:hover {
  transform: translateY(-5px);
  box-shadow: 0 8px 16px rgba(0,0,0,0.1);
  border-color: #ff8c42;
}

.project-card h3 {
  color: #ff8c42;
  margin-top: 0;
  margin-bottom: 10px;
  font-size: 1.3em;
}

.project-meta {
  color: #666;
  font-size: 0.9em;
  margin-bottom: 12px;
  font-style: italic;
}

.project-description {
  color: #333;
  line-height: 1.6;
  margin-bottom: 15px;
}

.project-tags {
  display: flex;
  flex-wrap: wrap;
  gap: 8px;
  margin-bottom: 15px;
}

.project-tag {
  background: #f5f5f5;
  color: #555;
  padding: 4px 12px;
  border-radius: 15px;
  font-size: 0.85em;
  border: 1px solid #e0e0e0;
}

.project-links {
  display: flex;
  gap: 12px;
  margin-top: 15px;
}

.project-link {
  color: #ff8c42;
  text-decoration: none;
  font-weight: 500;
  transition: color 0.2s;
}

.project-link:hover {
  color: #e67a2e;
  text-decoration: underline;
}
</style>

<div class="project-cards">
  
  <div class="project-card">
    <h3>A Long-Term Consistent Video World Model</h3>
    <div class="project-meta">2022 - 2023</div>
    <div class="project-description">
       A real-time world-model that generates continuous video streams while maintaining long-horizon coherence. Designed for interactive, low-latency useï¼Œsupports real-time updates from user inputs or events while keeping the world consistentâ€”so actions have lasting consequences and the scene remains logically aligned over time. 
    </div>
    <div class="project-tags">
      <span class="project-tag">World Models</span>
      <span class="project-tag">Video Generation</span>
      <span class="project-tag">Temporal Consistency</span>
      <span class="project-tag">Real-Time Inference</span>
    </div>
    <div class="project-links">
      <a href="#" class="project-link">ðŸŽ¬ Demo</a>
      <a href="#" class="project-link">ðŸ“Š Case Study</a>
    </div>
  </div>



<div class="project-cards">
  
  <div class="project-card">
    <h3>Multi-Modal Region-Aware Image Generation Framework</h3>
    <div class="project-meta">2022 - 2023</div>
    <div class="project-description">
      An advanced image editing system that empowers users with precise, region-specific control over AI-generated content. This innovative framework introduces an intuitive interaction paradigm where users can directly select and manipulate specific regions within an image, enabling targeted modifications while preserving the integrity of unselected areas.
    </div>
    <div class="project-tags">
      <span class="project-tag">Diffusion Models</span>
      <span class="project-tag">Multi-Modal Learning</span>
      <span class="project-tag">E-commerce AI</span>
      <span class="project-tag">Region Control</span>
    </div>
    <div class="project-links">
      <a href="#" class="project-link">ðŸŽ¬ Demo</a>
      <a href="#" class="project-link">ðŸ“Š Case Study</a>
    </div>
  </div>

  <div class="project-card">
    <h3>Ultra-High Fidelity 4Ã— Image Super-Resolution via Progressive Diffusion</h3>
    <div class="project-meta">2022 - 2023</div>
    <div class="project-description">
      A novel diffusion-based super-resolution framework designed to achieve 4Ã— upscaling with ultra-high fidelity image reconstruction. leveraging the power of denoising diffusion probabilistic models (DDPMs) combined with progressive refinement strategies and perceptual optimization techniques to generate photorealistic high-resolution images from low-resolution inputs.
    </div>
    <div class="project-tags">
      <span class="project-tag">Diffusion Models</span>
      <span class="project-tag">Super-Resolution</span>
      <span class="project-tag">Image Reconstruction</span>
    </div>
    <div class="project-links">
      <a href="#" class="project-link">ðŸ“„ Paper</a>
      <a href="#" class="project-link">ðŸ’» Code</a>
    </div>
  </div>

  <div class="project-card">
    <h3>AI-Powered Precision Background Removal</h3>
    <div class="project-meta">2022 - 2023</div>
    <div class="project-description">
      High-performance background removal system leveraging deep learning for instant, accurate results. Features intelligent edge detection and matting algorithms that handle challenging scenarios including intricate hair details, fur textures, and complex lighting conditions. Delivers professional-grade cutouts in seconds, ideal for e-commerce platforms, photography studios, and automated content generation workflows.
    </div>
    <div class="project-tags">
      <span class="project-tag">Deep Matting</span>
      <span class="project-tag">Semantic Segmentation</span>
      <span class="project-tag">U-Net</span>
      <span class="project-tag">Alpha Matting</span>
      <span class="project-tag">Computer Vision</span>
      <span class="project-tag">PyTorch</span>
    </div>
    <div class="project-links">
      <a href="#" class="project-link">ðŸ“„ Paper</a>
      <a href="#" class="project-link">ðŸ’» Code</a>
      <a href="#" class="project-link">ðŸŽ¬ Demo</a>
    </div>
</div>

<div class="project-card">
    <h3>PromptPalette: Frequency-Aware Text Fusion for Robust Diffusion Guidance</h3>
    <div class="project-meta">2022 - 2023</div>
    <div class="project-description">
       A frequency-aware adaptive text fusion module designed to strengthen diffusion guidance for complex prompts. The key idea is to explicitly model and re-balance high-frequency and low-frequency textual information, and then fuse them into a unified guidance representation that is dynamically conditioned on the promptâ€™s internal frequency structure.
    </div>
    <div class="project-tags">
      <span class="project-tag">Diffusion Models</span>
      <span class="project-tag">Text-to-Image</span>
      <span class="project-tag">Text Fusion</span>
    </div>
    <div class="project-links">
      <a href="#" class="project-link">ðŸ“„ Paper</a>
      <a href="#" class="project-link">ðŸ’» Code</a>
      <a href="#" class="project-link">ðŸŽ¬ Demo</a>
    </div>
</div>
